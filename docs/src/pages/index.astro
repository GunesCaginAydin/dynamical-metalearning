---
import BaseLayout from "../layouts/base-layout.astro"
---
<BaseLayout title="">
    <p class="abstract">
        In-context learning has emerged as a key capability of modern neural architectures. While its impact has been significant in domains such as natural language processing, computer vision, and policy generation, its potential for system identification remains underexplored in robotics. Building upon prior work on meta-learnable dynamical modeling with Transformers, we propose a methodology for predicting end-effector poses and joint positions from torque signals for each robotic joint — without requiring prior knowledge of the system’s physical parameters — using diffusion models. In the first part of this work, we enhance the RoboMorph framework by improving dataset generation through large-scale simulation with NVIDIA Isaac Gym, which we also adopt as a baseline for comparison. We then train and compare two complementary in-context learning architectures: a Transformer-based model and a Diffuser-based model, applied to the dynamic behavior of the Franka Emika Panda and KUKA Allegro robotic platforms. To explore different ERNSI Workshop 2025 configurations of the system identification problem using Diffusers, we frame it from multiple perspectives, leveraging classifier guidance, trajectory inpainting, and receding horizon approaches for improved trajectory estimation. Our aim is to investigate the implications of this approach for online control. We demonstrate that our meta-learned models can perform fast online inference, making them suitable for real-time applications. Furthermore, we exploit the inherent flexibility of diffusion models to condition on external signals at inference time — such as controller parameters — enabling enhanced in-context system identification. We conduct extensive benchmarking across a variety of Cartesian and joint space tasks generated in Isaac Gym. Code and datasets will be released to foster reproducibility and further research. 
    </p>

    <div class="intro">
        <p>
            Considering the simplified system identification problem presented on the work of Forgione et.al., the dynamic identification problem of any dynamical system may be reduced to a horizon planning problem. For the context and horizon lengths m and N and the related action-observation pairs (u (i) 1:N , y (i) 1:N , the meta-learning black box system identification model is: 
            <br>
            <br>
            yˆseq = Mϕ(uctx, yctx, useq)
            <br>
            <br>
            where the system identification model Mϕ is learnable with feedforward and feedback controller implementations. For the case of feedforward control, the action input represents feedforward controller torque outputs u = Tnom. For the other case of feedback control, the action input may either represent the feedback controller torque outputs u = Kp∆ϵ + Kd∆δϵ + Ki R ∆ϵ, feedback controller reference trajectory u = uref or feedback controller gain schedule u = concat(Kp, Kd, Ki) throughout the horizon. 
            <br>
        </p>
        <img src="" alt="x" class="intro-img">
    </div>
    <div class="methods">
        <p>
            Dynamical models are learnable with various different neural architectures. Since most of these architectures are in one way or another being used for some modeling tasks, in many ways, it is a matter of adapting the specific architectures to the needs of the problem, which is, mapping temporal high dimensional inputs to outputs. To that extent, we consider chiefly autoregressive (transformers) and non-autoregressive (diffusers) architectures.
            <br>
            <br>
            Autoregressive Architectures: We mainly use transformers as candidate architectures for autoregressive inference, owing clearly to the recent success in their sequential processing capabilities. Forgione et.al. suggests modifying the vanilla transformer architecture to account for temporal high dimensional input/output pairs that shows promising results in system and class identification tasks. We employ these models directly in our approach.
            <br>
            <br>
            Non-Autoregressive Architectures: Non autoregressive inference, even though by nature is not synonymous with sequential processes, still is extremely adept in many contemporary ML/AI problems. To that extent, we choose to adapt generative architectures using a diffusion process backbone for system identification tasks. 
            <br>
            <br>    
            Janner et.al. proposes a novel convolutional diffusion architecture that inpaints whole input/output state trajectories as action policy generators. Our diffuser model is based on this where both inputs and outputs are selectively inpainted according to a given context and the action policy generation process is modified to be representative of the identification/estimation tasks at hand.
            Another similar diffusion-based architecture is proposed by Chi et.al. where trajectories are conditioned instead of inpainted through the use of convolutional Unets or attention-based transformers. This being an action policy generation problem is again modified to fit the identification/estimation tasks at hand.
        </p>
        <div class="arch-images">
            <img alt="x" class="img1">
            <img alt="x" class="img2">
            <img alt="x" class="img3">
        </div>
    </div>

    <div class="arch-comp">
        <p>
        Janner et.al. proposes a novel convolutional diffusion architecture that inpaints whole input/output state trajectories as action policy generators. Our diffuser model is based on this where both inputs and outputs are selectively inpainted according to a given context and the action policy generation process is modified to be representative of the identification/estimation tasks at hand.
        Another similar diffusion-based architecture is proposed by Chi et.al. where trajectories are conditioned instead of inpainted through the use of convolutional Unets or attention-based transformers. This being an action policy generation problem is again modified to fit the identification/estimation tasks at hand.
        </p>
    </div>

    <div class="context-tests">
        <p>
        Janner et.al. proposes a novel convolutional diffusion architecture that inpaints whole input/output state trajectories as action policy generators. Our diffuser model is based on this where both inputs and outputs are selectively inpainted according to a given context and the action policy generation process is modified to be representative of the identification/estimation tasks at hand.
        Another similar diffusion-based architecture is proposed by Chi et.al. where trajectories are conditioned instead of inpainted through the use of convolutional Unets or attention-based transformers. This being an action policy generation problem is again modified to fit the identification/estimation tasks at hand.
        </p>
    </div>

    <div class="sim2real-transformer">
        <p>
        Janner et.al. proposes a novel convolutional diffusion architecture that inpaints whole input/output state trajectories as action policy generators. Our diffuser model is based on this where both inputs and outputs are selectively inpainted according to a given context and the action policy generation process is modified to be representative of the identification/estimation tasks at hand.
        Another similar diffusion-based architecture is proposed by Chi et.al. where trajectories are conditioned instead of inpainted through the use of convolutional Unets or attention-based transformers. This being an action policy generation problem is again modified to fit the identification/estimation tasks at hand.
        </p>
    </div>

    <div class="sim2real-diffuser">
        <p>
        Janner et.al. proposes a novel convolutional diffusion architecture that inpaints whole input/output state trajectories as action policy generators. Our diffuser model is based on this where both inputs and outputs are selectively inpainted according to a given context and the action policy generation process is modified to be representative of the identification/estimation tasks at hand.
        Another similar diffusion-based architecture is proposed by Chi et.al. where trajectories are conditioned instead of inpainted through the use of convolutional Unets or attention-based transformers. This being an action policy generation problem is again modified to fit the identification/estimation tasks at hand.
        </p>
    </div>

</BaseLayout>

<style>
    .abstract {
        text-align: center;
        color: #005828;
        display: none;
        
    }

    .intro {
        text-align: right;
        display: flex;

    }

    .intro-img {
        width: 1000px;
        margin: 1em 4em
    }
    
    .arch-images {
        display: flex;
        justify-content: space-between;
    }

    .methods {

    }

    .arch-comp {
        text-align: left;

    }

    .context-tests {
        text-align: left;

    }

    .sim2real-transformer {
        text-align: left;

    }
    
    .sim2real-diffuser {
        text-align: left;

    }

    @media screen and (max-width : 1000px) {

	}
</style>