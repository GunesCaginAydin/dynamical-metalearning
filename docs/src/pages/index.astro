---
import BaseLayout from "../layouts/base-layout.astro"
---
<BaseLayout title="Dynamical Metalearning">
    <div class="home-page">
    <p class="abstract">
        In-context learning has emerged as a key capability of modern neural architectures. While its impact has been significant in domains such as natural language processing, computer vision, and policy generation, its potential for system identification remains underexplored in robotics. Building upon prior work on meta-learnable dynamical modeling with Transformers, we propose a methodology for predicting end-effector poses and joint positions from torque signals for each robotic joint — without requiring prior knowledge of the system’s physical parameters — using diffusion models. In the first part of this work, we enhance the RoboMorph framework by improving dataset generation through large-scale simulation with NVIDIA Isaac Gym, which we also adopt as a baseline for comparison. We then train and compare two complementary in-context learning architectures: a Transformer-based model and a Diffuser-based model, applied to the dynamic behavior of the Franka Emika Panda and KUKA Allegro robotic platforms. To explore different ERNSI Workshop 2025 configurations of the system identification problem using Diffusers, we frame it from multiple perspectives, leveraging classifier guidance, trajectory inpainting, and receding horizon approaches for improved trajectory estimation. Our aim is to investigate the implications of this approach for online control. We demonstrate that our meta-learned models can perform fast online inference, making them suitable for real-time applications. Furthermore, we exploit the inherent flexibility of diffusion models to condition on external signals at inference time — such as controller parameters — enabling enhanced in-context system identification. We conduct extensive benchmarking across a variety of Cartesian and joint space tasks generated in Isaac Gym. Code and datasets will be released to foster reproducibility and further research. 
    </p>

    <div class="intro">
        <img src="trf_cond.png" alt="system identification pipeline" class="intro-img1">
        <div>
        <p>
            Considering the simplified system identification problem presented on the work of <a href="https://arxiv.org/pdf/2308.13380">Forgione et.al.</a>, the dynamic identification problem of any dynamical system may be reduced to a horizon planning problem. For the context and horizon lengths <i>m</i> and <i>N</i> and the related action-observation pairs <br> <i>(u - y)</i> , the meta-learning black box system identification model is: 
            <br>
            <br>
                $$y^{'s'} = M_{'ϕ'}(y^{'q'},u^{'q'},u^{'s'})$$
            <br>
            <br>
            which is learnable with support and query datasets as with the generic meta-learning framework . Physically, the action trajectory represents either the feedforward controller torque outputs or feedback controller torque outputs, reference trajectories and gains. The corresponding observed trajectory stands for the complete kinematics in <i>14D</i> joint and cartesian spaces. The proposed input-output paradigm is as below.
        </p>
        </div>
    </div>
    <img src="trf.png" alt="input-output paradigm for query and support sets in a metalearning identification framework" class="intro-img2" width="400px">
    <div class="methods">
        <p>
            Dynamical models are learnable with <highlight class="highlight">different neural architectures</highlight>.
            <br>
            <highlight class="highlight">Autoregressive Architectures</highlight>: We train 2 transformer based autoregressive architectures <highlight class="highlight">(sequential transformers, conditioned diffusion transformers)</highlight> following the metalearning paradigm suggested in <a href="https://arxiv.org/pdf/2308.13380">Forgione et.al.</a>. Transformers process information sequentially with input/output pairs in an instance of time at each run through the encoder/decoder compound. Sequential transformers and conditioned diffusion transformers are adapted from <a href="https://arxiv.org/pdf/2308.13380">Forgione et.al.</a> and <a href="https://arxiv.org/pdf/2308.13380">Forgione et.al.</a> respectively.
        <div class="trf-images">
            <img src="trf.png" alt="base transformer sketch" width="500px">
            <img src="trf_cond.png" alt="conditional diffusion transformer sketch" width="300px">
        </div>
            <highlight class="highlight">Non-Autoregressive Architectures</highlight>: We adapt 2 diffusion based nonautoregressive architectures <highlight class="highlight">(inpainted diffusers, conditional diffuser)</highlight> following the same metalearning paradigm. Diffuse probabilistic estimation is not directly sequential and temporal connectivity is mainly inferred from local properties. Inpainted diffusers and conditional diffusers are extensions of <a href="https://arxiv.org/pdf/2308.13380">Forgione et.al.</a> and <a href="https://arxiv.org/pdf/2308.13380">Forgione et.al.</a> respectively.
        </p>
        <div class="dif-images">
            <img src="dif.png" alt="inpainted diffusion CNN sketch" width="500px">
            <img src="cnn_cond.png" alt="conditional diffusion CNN sketch" width="300px">
        </div>
    </div>

    <div class="arch-comp">
        <p>
            For system identification, transformer based autoregressive models are superior.
        </p>
        <div class="dif-images">
            <img src="arch-comp.png" alt="comparison of 4 neural architectures on system identification task using MS and CH signals" width="600px">
            <div>
                <img src="horizon-pos-trf.png" alt="estimation on cartesian position with transformer models" class="img1">
                <img src="err-pos-trf.png" alt="errors on cartesian position with transformer models" class="img2">
            </div>
        </div>
    </div>

    <div class="context-tests">
        <p>
            Context matters: query set size is critical in metalearning. However transformer and diffuser based approaches have different sensitivities to query set size.
        </p>
        <div class="dif-images">
            <img alt="x" class="img1">
            <img alt="x" class="img2">
        </div>
    </div>

    <div class="sim2real-transformer">
        <p>
            Transformer based approaches perform well also in basic sim2real trajectories. A major drawback is the computational requirements due to memory limitations.
        </p>
        <div class="dif-images">
            <img alt="x" class="img1">
            <img alt="x" class="img2">
        </div>
    </div>

    <div class="sim2real-diffuser">
        <p>
            Diffusion based alternatives have inference time spatial flexibility due to convolutional layers. This comes at a slight cost in performance but overall, especially for periodic signals, extrapolation is facilitated.
        </p>
        <div class="dif-images">
            <img alt="x" class="img1">
            <img alt="x" class="img2">
        </div>
    </div>
    </div>
</BaseLayout>

<style>
    .home-page {

    }
    .home-page a {
        color:  #005828;;
        text-decoration: none;
    }
    .abstract {
        text-align: center;
        color: #005828;
        display: none;
        
    }

    .intro {
        text-align: left;
        display: flex;

    }

    .intro-img1 {
        width: 1000px;
        margin: 1em 4em
    }
    
    .intro-img2 {
        width: 1000px;
        margin: 4em 0em;
    }

    .trf-images {
        display: flex;
        justify-content: space-around;
        margin: 4em 0em;
    }
    .dif-images {
        display: flex;
        justify-content: space-around;
        margin: 4em 0em;
    }

    .methods {

    }

    .arch-comp {
        text-align: left;

    }

    .context-tests {
        text-align: left;

    }

    .sim2real-transformer {
        text-align: left;

    }
    
    .sim2real-diffuser {
        text-align: left;

    }

    .highlight {
        color: #005828;
    }

    @media screen and (max-width : 1000px) {

	}
</style>