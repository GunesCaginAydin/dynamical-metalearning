# CLASSIFY 

[[Paper]]() 
[[Data]]()
[[Colab (data generation)]]()
[[Colab (sim2sim)]]()
[[Colab (sim2real)]]()

[Gunes Cagin Aydin](https://github.com/Gunesnes)<sup>1</sup>,
[Loris Roveda](https://www.supsi.ch/loris-roveda)<sup>2</sup>,
[Asad Ali Shadid](https://www.supsi.ch/en/asad-ali-shahid)<sup>2</sup>,
[Angelo Morencelli](https://www.supsi.ch/en/angelo-moroncelli-)<sup>1</sup>,

<sup>1</sup>Politecnico di Milano,
<sup>2</sup>SUPSI/IDSIA,

(Insert Media)

This work is the continuation of previous works on system and class modeling with in-context learning through direct implementation of modern neural network architectures. 

[1]	From system models to class models: An in-context learning paradigm

[2]	RoboMorph: In-Context Meta-Learning for Robot Dynamics Modeling

Our main contribution can be grouped under 3 main branches:

1)	improved dynamical system identification with metalearning transformer models
	
2) 	implementation of diffusion models as a competitor neural architecture
	
3)	implementation of isaacgym based controllers for controller modeling and sim2real tasks
	
# Repository organization

Our approach is comprised of 2 interworking modules: data_generation, sys_identification. The former utilizes isaacgym environments for synthetic data generation while the latter performs training, finetuning and testing of the data on Franka Emika Panda and Kuka Allegro robotic manipulators. Below are the module hierarchies...

```
‚îî‚îÄ‚îÄ data_generation
    ‚îú‚îÄ‚îÄ {data_tensors} : .pt
    ‚îÇ   ‚îî‚îÄ‚îÄ train
    ‚îÇ       ‚îú‚îÄ‚îÄ MG1
    ‚îÇ       ‚îú‚îÄ‚îÄ MG2
    ‚îÇ       ‚îú‚îÄ‚îÄ ...
    ‚îÇ       ‚îî‚îÄ‚îÄ MGC
    ‚îÇ   ‚îî‚îÄ‚îÄ test
    ‚îÇ       ‚îú‚îÄ‚îÄ T1
    ‚îÇ       ‚îú‚îÄ‚îÄ T2
    ‚îÇ       ‚îú‚îÄ‚îÄ ...
    ‚îÇ       ‚îî‚îÄ‚îÄ TC
    ‚îÇ
    ‚îú‚îÄ‚îÄ {data_objects} : .json
    ‚îÇ   ‚îú‚îÄ‚îÄ MG1
    ‚îÇ   ‚îú‚îÄ‚îÄ MG2
    ‚îÇ   ‚îú‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ MGC
    |
    ‚îú‚îÄ‚îÄ {plots} : .png  
    ‚îÇ   ‚îú‚îÄ‚îÄ aux
    ‚îÇ   ‚îú‚îÄ‚îÄ MG1
    ‚îÇ   ‚îú‚îÄ‚îÄ MG2
    ‚îÇ   ‚îú‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ MGC
    |
    |
    ‚îú‚îÄ‚îÄ {datageneration_modules} : .py
    ‚îÇ   ‚îú‚îÄ‚îÄ randomenvs.py
    ‚îÇ   ‚îú‚îÄ‚îÄ controllers.py
    ‚îÇ   ‚îú‚îÄ‚îÄ genutil.py
    ‚îÇ   ‚îî‚îÄ‚îÄ genfranka.py
    |
    ‚îî‚îÄ‚îÄ {gen.sh}
```

```
‚îî‚îÄ‚îÄ sys_identification
    ‚îú‚îÄ‚îÄ {models} : .pt
    ‚îÇ   ‚îú‚îÄ‚îÄ MG1
    ‚îÇ   ‚îú‚îÄ‚îÄ MG2
    ‚îÇ   ‚îú‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ MGC
    ‚îÇ
    ‚îú‚îÄ‚îÄ {logs} : .txt
    ‚îÇ   ‚îú‚îÄ‚îÄ MG1
    ‚îÇ   ‚îú‚îÄ‚îÄ MG2
    ‚îÇ   ‚îú‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ MGC
    |
    ‚îú‚îÄ‚îÄ {plots} : .png  
    ‚îÇ   ‚îú‚îÄ‚îÄ aux
    ‚îÇ   ‚îú‚îÄ‚îÄ MG1
    ‚îÇ   ‚îú‚îÄ‚îÄ ...
    ‚îÇ   ‚îî‚îÄ‚îÄ MGC
    |
    ‚îú‚îÄ‚îÄ {architectures} : .py
    ‚îÇ   ‚îî‚îÄ‚îÄ transformer
    ‚îÇ       ‚îî‚îÄ‚îÄ transformer_sim.py
    ‚îÇ   ‚îî‚îÄ‚îÄ diffuser
    ‚îÇ       ‚îú‚îÄ‚îÄ diffuser_utils.py
    ‚îÇ       ‚îú‚îÄ‚îÄ diffuser_models.py
    ‚îÇ       ‚îî‚îÄ‚îÄ diffuser_sim.py
    ‚îÇ   ‚îî‚îÄ‚îÄ recedinghorizon
    ‚îÇ       ‚îú‚îÄ‚îÄ rechor_utils.py
    ‚îÇ       ‚îú‚îÄ‚îÄ rechor_models.py
    ‚îÇ       ‚îî‚îÄ‚îÄ rechor_sim.py
    |
    ‚îú‚îÄ‚îÄ {sysidentification_modules} : .py
    ‚îÇ   ‚îú‚îÄ‚îÄ losses.py
    ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py
    ‚îÇ   ‚îú‚îÄ‚îÄ utils.py
    ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py
    ‚îÇ   ‚îú‚îÄ‚îÄ train.py
    ‚îÇ   ‚îî‚îÄ‚îÄ test.py
    ‚îÇ
    ‚îú‚îÄ‚îÄ {test.sh}
    ‚îî‚îÄ‚îÄ {train.sh}
```

## Data Generation

We decided to tackle data generation with varying datasets that have different randomization amounts and input/output generators. Most important points of variance in our investigation is on:

* rigid body properties, dof states, dof properties

* isaacgym internal controller dof properties

* osc / pid / joint_pid controller gains

* input trajectories

### Training Datasets
1) MG1: base dataset MS/CH

2) MG2: base + 10% randomization on states and props
 
3) MG3: base + 6D orientation

4) MG4: base + frequency ranzomization

5) MG5: base + out-of-distribution frequency randomization
 
6) MG6: base + isaacgym internally measured torques

7) MGOSC: base dataset VS/FS/FC

8) MGC: base dataset osc/pid/joint_pid

### Testing Datasets
1) T1: MS/CH

2) T2: 25-50% randomization

3) T3: out-of-distribution frequencies

4) T4: IMP/TRAPZ

5) TOSC: VS/FS/FC

6) TC: osc/pid/joint_pid

### Creating a Dataset

## System Identification

### sim2sim

### sim2real

### Training / Testing / Finetuning

For data generation, it is important to modify gen.sh for specific needs. A most simplistic use case could be to generate data for franka emika panda
subjected to direct feedforward joint torques, in which case the generation script is callable as:

./gen.sh -> python genfranka.py xxx

For training, it is important to modify gen.sh for specific needs. A most simplistic use case could be to generate data for franka emika panda
subjected to direct feedforward joint torques, in which case the generation script is callable as:

./gen.sh -> python genfranka.py xxx

For testing, it is important to modify gen.sh for specific needs. A most simplistic use case could be to generate data for franka emika panda
subjected to direct feedforward joint torques, in which case the generation script is callable as:

./gen.sh -> python genfranka.py xxx

# Installation and requirements

## Environments

### IsaacGym

Download the Isaac Gym Preview 4 release from the website (https://developer.nvidia.com/isaac-gym), then follow the installation instructions in the documentation. We highly recommend using a conda environment to simplify set up. 

### Conda Environment

Please replicate the conda environment for reproduciblity

## Hardware requirements

This projects requires a modern GPU. We used a combination of Nvidia RTX4070 and Nvidia A100 GPUs. However, most of the work is still possible to do on older gen Nvida 3000 GPUs.

# Citing

If you find this work useful, please consider citing it.

@article {forgione2023from,
author={Forgione, Marco and Pura, Filippo and Piga, Dario},
journal={IEEE Control Systems Letters},
title={From System Models to Class Models:
An In-Context Learning Paradigm},
year={2023},
volume={7},
number={},
pages={3513-3518},
doi={10.1109/LCSYS.2023.3335036}
}
## üè∑Ô∏è License

This repository is released under the MIT license. See [LICENSE](LICENSE) for additional details.

## üôè Acknowledgement

* Our [`transformer_sim`]() architecture is adapted from [In-context learning for model-free system identification](https://github.com/forgi86/sysid-transformers).
* Our [`diffuser_sim`]() architecture is adapted from [Planning with Diffusion for Flexible Behavior Synthesis](https://github.com/jannerm/diffuser).
* Our [`rechor_sim`]() architecture is adapted from [Diffusion Policy](https://github.com/real-stanford/diffusion_policy).
* Our [`data_generation`]() implementation is adapted from [RoboMorph: In-Context Meta-Learning for Robot Dynamics Modeling](https://github.com/izzab1926/RoboMorph).


